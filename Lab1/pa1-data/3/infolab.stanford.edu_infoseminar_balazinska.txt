skew and failures during parallel data processing magda balazinska university of washington in the database group at the university of washington the nuage project studies various aspects of data intensive scalable computing in this talk we present two of our recent results we first present skewreduce a new system implemented on top of hadoop that drastically improves load balance in complex user defined operations where processing times depend not only on the total amount of data but also on the data value distributions skewreduce is designed to support a common class of applications that we call feature extraction analysis where this problem frequently arises experiments on real data demonstrate that skewreduce can improve execution times by a factor of up to 8 compared to a naive mapreduce implementation second we present ftopt a new approach for making online parallel query plans fault tolerant ftopt provides intra query fault tolerance without blocking additionally it does so by using different fault tolerance techniques at different operators within a query plan enabling each operator to use a different fault tolerance strategy leads to a space of fault tolerance plans amenable to cost based optimization ftopt comprises a protocol for mixing and matching fault tolerance techniques within a single query plan and an optimizer for selecting the technique to use in order to minimize the expected processing time with failures for the entire query experiments show that with as little as one failure the choice of fault tolerance approach can result in 70 difference in query runtimes that often hybrid query plans lead to the best performance and that our optimizer is able to select a winning plan
