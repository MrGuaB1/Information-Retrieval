using the babar database event store data management analysis fds outage schedule locked fds data mgmt server assignments search site map event store data management normally only micro and tag level data is kept on disk permanently raw rec esd mini data is kept on tape and must be staged in before the job is run there are three ways of getting staged data on disk they offer different approaches based on your needs temporarily staging data to disk the collstagein command can temporarily load data to disk this is a solution when you only want to run a job on a specific collection once the help option will describe usage and options additional information is available in selected application section see collstagein a typical command to stage the raw data for collection users me myevents is collstagein wait include raw users me myevents when data is staged e mail will be sent to you e mail will be sent for each host the data is staged in to use this command in a script that you submit to a batch queue there is an option wait which blocks the exist until all the files appear on disk this option doesn t time out the script in case if the data can t be staged the data you staged using the collstagein command becomes eligible for purging off disk 12 hours after the last access to it actual purging time depends on overall disk usage and other staging activity the rule is the oldest eligible for purging is purged first when there is a need to make room for new data therefore one should not assume that the data is on disk the day after the collstagein command was run the best way of ensuring that the data is on disk at job run time is to use collstagein with the wait option in a script for batch submission long term kept data you can use keptdata service when you need a collection to be available on disk for a relatively long time weeks or months or when you need to access data several times during shorter period few days to use keptdata service for either submitting a request or checking what's already on disk go to the following urls command line version is not available yet for physboot1 see http www slac stanford edu babar internal keptdata ana3 requests html for physboot2 see http www slac stanford edu babar internal keptdata ana3 requests html for analboot2 see http www slac stanford edu babar internal keptdata ana2 requests html for sp3analboot see http www slac stanford edu babar internal keptdata sp3 requests html for simuboot slac data only see http www slac stanford edu babar internal keptdata sp4 requests html data from newer physics federations and mc data produced by remote sites is not covered by this server it is being worked on if you discover that one of the collections listed on keptdata pages does not have all the listed data on disk that's an error please let us know collections of specific digis the above method stores large numbers of contiguous events on disk this is only efficient if you want to look at a large fraction of those events for certain purposes you want to take a comparatively sparse collection of events and reprocess them from digis we provide digi copies of collections to make this more efficient once you have a collection of events even if quite sparse we can load a copy of just the digis from just these events onto disk where they will stay until you delete them this is also useful when you want to export such skim collections to your institution note that we are currently only copying the raw data digis you can then run bear on these collections as often as needed to reprocess the data for your own use note that we are currently only doing this for the analboot2 federation paul raines has provided a web based system for making and checking the requests it's available from http www slac stanford edu babar internal collreq requests html you need a babar account name and password to use it to check a particular run or collection enter the run range and press show the status codes are requested in the queue pending actually being processed done finished and thought to be ok failed failed in processing will be retried on hold failed twice now pending some intervention cancelled has been removed from the queue to add a collection to the list to be copied use the make request button it will open a panel in which to enter the input and output collections and the run number of the start of the data we use that run number to optimize the order in which we process tapes generally the output digi collections should have digis in their collection names for example copy from groups groupname collection to groups groupname digis collection see also the information above for examples there are also command line tools for making large numbers of requests if you d like to use these please contact bob jacobsen directly babar public site slac news links who's who contact us page owner jacek becla last update june 13 2002
