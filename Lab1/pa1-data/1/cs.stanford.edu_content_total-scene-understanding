total scene understanding stanford computer science skip to main content area home home contact us directions school of engineering stanford university about us contact us directions giving to cs strategic plan jobs faculty opening lecturer opening people faculty staff students alumni in memoriam education courses undergraduate masters phd admissions research events & seminars faculty profiles projects computer forum home total scene understanding given an image we propose a hierarchical generative model that classifies the overall scene recognizes and segments each object component as well as annotates the image with a list of tags to our knowledge this is the first model that performs all three tasks in one coherent framework for instance a scene of a polo game consists of several visual objects such as human horse grass etc in addition it can be further annotated with a list of more abstract eg dusk or visually less salient eg saddle tags our generative model jointly explains images through a visual model and a textual model visually relevant objects are represented by regions and patches while visually irrelevant textual annotations are influenced directly by the overall scene class we propose a fully automatic learning framework that is able to learn robust scene models from noisy web data such as images and user tags from flickr com we demonstrate the effectiveness of our framework by automatically classifying annotating and segmenting images from eight classes depicting sport scenes in all three tasks our model significantly outperforms state of the art algorithms project image artificial intelligence stanford university 353 serra mall stanford california 94305 650 723 2300 terms of use copyright complaints
