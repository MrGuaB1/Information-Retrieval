abstract oded schwartz algorithms have two kinds of costs arithmetic and communication by communication we mean either moving page 1 abstract oded schwartz algorithms have two kinds of costs arithmetic and communication by communication we mean either moving data between levels of a mem ory hierarchy in the sequential case or over a network connecting proces sors in the parallel case the communication of an algorithm often costs signi_cantly more time and energy than its arithmetic lower bounds on the communication costs thus provide performance scalability limits and motivate the search for communication minimizing algorithms several communication minimizing algorithms and lower bounds were discovered starting in the late 60's recently lower bounds for many dense linear algebra algorithms have been shown these were followed by the discovery of corresponding communication minimizing algorithms in one approach we show that the communication costs of algorithms is closely related to the expansion properties of the corresponding compu tation graphs we demonstrate this on strassen's fast matrix multiplica tion and other algorithms and obtain the _rst lower bounds on their com munication costs for both sequential and parallel models these bound are optimal for the sequential case as they are attainable by existing nat ural implementations we use the graph expansion approach to devise implementations that attain the communication costs lower bounds for the parallel model as well
