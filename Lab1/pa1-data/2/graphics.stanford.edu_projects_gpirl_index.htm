nonlinear inverse reinforcement learning with gaussian processes supplementary materials nonlinear inverse reinforcement learning with gaussian processes supplementary materials sergey levine stanford university zoran popovic university of washington vladlen koltun stanford university this webpage provides supplementary materials for the nips 2011 paper nonlinear inverse reinforcement learning with gaussian processes the paper can be viewed here the following materials are provided derivation of likelihood partial derivatives and description of random restart scheme pdf full results of comparison between gpirl and previous irl algorithms pdf complete matlab source code in a modular extensible framework zip video of the learned policies and human demonstrations on the highway environment see below 1 supplementary video the video first shows an example demonstration by a human expert of a policy that avoids exceeding speed 2 near police cars we then show an optimal expert executing this policy based on the reward function described in the paper the optimal demonstration is shown for reference and is not provided to the irl algorithms finally we show the policies learned by the three best performing irl algorithms for this task gpirl maxent lp and firl the video is provided below using flash and available as a divx avi file here 00 00
