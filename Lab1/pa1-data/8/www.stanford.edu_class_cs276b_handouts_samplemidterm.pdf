cs 276b sample midterm questions 1 web size estimation a when estimating the size of the web using a random walk on web pag page 1 cs 276b sample midterm questions 1 web size estimation a when estimating the size of the web using a random walk on web pages we do not use the teleport to a random web page operation used in the pagerank computation why not b consider the capture recapture strategy for estimating the size of the web we draw a random number of pages from one search engine and check whether they are indexed in a second search engine consider the test for whether the chosen page is present in another engine list at least two sources of bias in this test c two web search engines a and b each generate a large number of pages uniformly at random from their indexes 30 of a's pages are present in b's index while 50 of b's pages are present in a's index what is the number of pages in a's index relative to b's d now let us consider a scenario in which we use two crawls to estimate the frequency of duplicates on the web web search engines a and b each crawl a random subset of the web of the same size some of the pages crawled will be duplicates exact textual copies of each other at different urls assume that duplicates are distributed uniformly amongst the pages crawled by a and b further for this exercise we will define a duplicate as a page that has exactly two copies no pages have more than two copies a indexes pages without duplicate elimination whereas b indexes only one copy of each duplicate page note the two random subsets have the same size before duplicate elimination if 45 of a's indexed urls are present in b's index while 50 of b's indexed urls are present in a's index what fraction of the web consists of pages that do not have a duplicate 2 web graph the in degree of web pages follows a distribution similar to zipf's law the kth most popular page has in degree proportional to 1 k 2.1 as the largest in degree value goes to infinity does the fraction of pages with in degree k grow stay the same or diminish page 2 solutions 1 web size estimation a pagerank is run on a set of known web pages that are already crawled we can teleport since we can randomly select pages from this set estimating the size of this subset of the web is trivial just count the point of web size estimation is that we don t already have an exhaustive list of the pages of interest so we can t teleport b 1 we assume that the population search engines draw from is the whole web it is not for example nonconnected non submitted pages are not part of the population 2 we assume that each page has the same probability to be drawn that is not correct popular important pages yahoo com are more likely to be drawn than obscure pages 3 duplicates c a 5 3 b d the size of a is pn if p is the sampling rate and n the size of the web let 1 2f be the proportion of non duplicates let b be the crawl with dups let b be the dup free version of b deterministically we know 1 a b pn 2 a b 45 a 45 b 50 b so that 3 b b 0.90 we expect 4 we expect that a b p 0.9 b p 0.9 pn 0.9 p 2n using 1 & 2 we have that 0.9 p 2n 0.45 pn so that 5 p 0.5 we now have p but still need to find f we expect b to have 2fp 2n dups with both copies in b so that fp 2n pages get dropped but using 3 the number dropped must be 0.10 b so that fp 2n 0.10 b 0.1 pn so that f 0.1 p 0.1 0.5 0.2 so f 0.2 1 2 f 60 of the web has no duplicates 2 it stays the same here the frequency at k is n i i k 1 1.2 1.2 1 1 the denominator converges to a constant for large n hence the frequency at k stays unchanged as n approaches infinity
