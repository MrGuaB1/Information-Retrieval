17.2 2 greedy techniques page 1 572 17 exploration here b b z u is computed using the bayes filter in robotics we only have a choice over the control action u we cannot pick z consequently we consider the conditional entropy of the control u with the measurement integrated out hb x u ez hb x z u 17.3 hb x z u p z x p x u x b x dz dx dx notice that this is only an approximation as the final expression inverts the oder of a summation and a logarithm the information gain associated with information gain action u in belief b is thus given by the difference ib u hp x ez hb x z u 17.4 17.2 2 greedy techniques the expected information gain lets us phrase the exploration problem as a decision theoretic problem of the type addressed in previous chapters in particular let r x u be the cost of applying control action u in state x here we assume r x u 0 to keep our notation consistent then the optimal greedy exploration for the belief b maximizes the difference between the in formation gain and the costs weighted by a factor   b argmax u  hp x ez hb x z u expected information gain r x u b x dx expected costs 17.5 the factor  relates information to the cost of executing u it specifies the value a robot assigns to information which measures the price it is willing to pay in terms of costs for obtaining information equation 17.5 resolves to  b argmax u  ez hb x z u r x u b x dx 17.6 argmax u r x u  hb x z u p z x p x u x dz dx b x dx in short to understand the utility of the control u we need to compute the expected entropy after executing u and observing this expected entropy is obtained by integrating over all possible measurements z that we might be
