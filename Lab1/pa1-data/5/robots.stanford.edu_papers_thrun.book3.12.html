sebastian thrun's homepage homepage research students courses robots papers videos press talks faq cv lab travel contact personal links reinforcement learning with self modifying policies by juergen schmidhuber jieyu zhao nicol n schraudolph a learner's modifiable components are called its policy an algorithm that modifies the policy is a learning algorithm if the learning algorithm has modifiable components represented as part of the policy then we speak of a self modifying policy smp smps can modify the way they modify themselves etc they are of interest in situations where the initial learning algorithm itself can be improved by experience this is what we call learning to learn how can we force some stochastic smp to trigger better and better self modifications the success story algorithm ssa addresses this question in a lifelong reinforcement learning context during the learner's life time ssa is occasionally called at times computed according to smp itself ssa uses backtracking to undo those smp generated smp modifications that have not been empirically observed to trigger lifelong reward accelerations measured up until the current ssa call this evaluates the long term effects of smp modifications setting the stage for later smp modifications smp modifications that survive ssa represent a lifelong success history until the next ssa call they build the basis for additional smp modifications solely by self modifications our smp ssa based learners solve a complex task in a partially observable environment poe whose state space is far bigger than most reported in the poe literature
