quiz 4 page 1 cs224n natural language processing spring 2008 weekly quiz quiz 4 1 in the ner task when the the suffix feature field fires it is actually quite indicative all else being equal what is a word that has the suffix field most likely to be person name organization movie name location not a named entity 2 what is not true about maxent models also known as log linear models it is trying to maximize the entropy while respecting observed evidences the weights for features need not sum up to 1 but must lie in 0 1 none of the above 3 which of the following is true an hmm is better than a memm because we can easily add arbitrary features in hmm the disadvantage of a discriminative model is that training and optimizing parameter weights is more expensive than for a generative model a trigram language model is making a markov assumption that the probability of a word depends on all the words that appear before it all of the above none of the above 4 a maximum entropy model takes the exponential vote for each class and normalize them to get a probability see lecture notes if there is a binary classification problem and vote c1 0.2 and vote c2 0.2 which of the following is true p c1 p c2 1 p c1 p c2 both of the above none of the above page 2 5 which of the following is true character substrings and word shapes are very indicative features for the ner task a cmm aka memm makes a single decision at a time conditioned on evidence from observations and also previous decisions if we apply a maxent classifier a non sequence model to an ner task then features can be from the observed context but not from what labels ner tags they have all of the above none of the above 6 in a maxent model a feature c is formed as the intersection of two features a and b if we are trying to predict many classes and using many features at once then when looking at the specific weights that a b and c have for a specific class which of the following statements is true if a and b agree in sign c will have the same sign c will have the sign of whichever a or b was greater in magnitude if a and b agree in sign c will have the opposite sign c could have either sign in general 7 for an hmm parameterized by a and given a set of observations o the problem of finding p a o is known as likelihood decoding learning encoding none of the above 8 which of the following graphs describe a generative model page 3 a & b a & c b & c 9 which of the following does not accomplish proper regularization a b c d all of them accomplish proper regularization 10 in maxent models we are trying to estimate the parameters w as which is equivalent to recall that the final form of p c x w in a maxent model is finding the optimal weights that satisfy the above equations then guarantees that the derivatives of this function are zero for all weights wc hat j or page 4 this condition then guarantees that which terms are equal none of the above
