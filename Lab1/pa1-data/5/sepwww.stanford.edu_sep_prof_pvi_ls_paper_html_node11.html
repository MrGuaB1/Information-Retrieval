conditioning the gradient next up previous print clean next why steepest descent is up iterative methods previous method of random directions conditioning the gradient often people do calculations by the method of steepest descent without realizing it often a result is improved in a single step or with a small number of steps many fewer than the number needed to achieve convergence this is especially true with images where the dimensionality is huge and where a simple improvement to the adjoint operator is sought three dimensional migration is an example in these cases it may be worthwhile to make some ad hoc improvements to the gradient that acknowledge the gradient will be a perturbation to the image and so should probably have an amplitude and spectrum like that of a more formal mathematical discussion of preconditioning is on page next up previous print clean next why steepest descent is up iterative methods previous method of random directions stanford exploration project 10 21 1998
