probabilistic approaches to relevance feedback next up previous contents index next an appraisal and some up the binary independence model previous probability estimates in practice contents index probabilistic approaches to relevance feedback we can use pseudo relevance feedback perhaps in an iterative process of estimation to get a more accurate estimate of the probabilistic approach to relevance feedback works as follows guess initial estimates of and this can be done using the probability estimates of the previous section for instance we can assume that is constant over all in the query in particular perhaps taking use the current estimates of and to determine a best guess at the set of relevant documents use this model to retrieve a set of candidate relevant documents which we present to the user we interact with the user to refine the model of we do this by learning from the user relevance judgments for some subset of documents based on relevance judgments is partitioned into two subsets and which is disjoint from we reestimate and on the basis of known relevant and nonrelevant documents if the sets and are large enough we may be able to estimate these quantities directly from these documents as maximum likelihood estimates 77 where is the set of documents in containing in practice we usually need to smooth these estimates we can do this by adding to both the count and to the number of relevant documents not containing the term giving 78 however the set of documents judged by the user is usually very small and so the resulting statistical estimate is quite unreliable noisy even if the estimate is smoothed so it is often better to combine the new information with the original guess in a process of bayesian updating in this case we have 79 here is the estimate for in an iterative updating process and is used as a bayesian prior in the next iteration with a weighting of relating this equation back to equation 59 requires a bit more probability theory than we have presented here we need to use a beta distribution prior conjugate to the bernoulli random variable but the form of the resulting equation is quite straightforward rather than uniformly distributing pseudocounts we now distribute a total of pseudocounts according to the previous estimate which acts as the prior distribution in the absence of other evidence and assuming that the user is perhaps indicating roughly 5 relevant or nonrelevant documents then a value of around is perhaps appropriate that is the prior is strongly weighted so that the estimate does not change too much from the evidence provided by a very small number of documents repeat the above process from step 2 generating a succession of approximations to and hence until the user is satisfied it is also straightforward to derive a pseudo relevance feedback version of this algorithm where we simply pretend that more briefly assume initial estimates for and as above determine a guess for the size of the relevant document set if unsure a conservative too small guess is likely to be best this motivates use of a fixed size set of highest ranked documents improve our guesses for and we choose from the methods of and 79 for re estimating except now based on the set instead of if we let be the subset of documents in containing and use add smoothing we get 80 and if we assume that documents that are not retrieved are nonrelevant then we can update our estimates as 81 go to step 2 until the ranking of the returned results converges once we have a real estimate for then the weights used in the value look almost like a tf idf value for instance using equation 73 equation 76 and equation 80 we have 82 but things aren t quite the same measures the estimated proportion of relevant documents that the term occurs in not term frequency moreover if we apply log identities 83 we see that we are now adding the two log scaled components rather than multiplying them exercises work through the derivation of equation 74 from and 3 i what are the differences between standard vector space tf idf weighting and the bim probabilistic retrieval model in the case where no document relevance information is available let be a random variable indicating whether the term appears in a document suppose we have relevant documents in the document collection and that in of the documents take the observed data to be just these observations of for each document in show that the mle for the parameter that is the value for which maximizes the probability of the observed data is describe the differences between vector space relevance feedback and probabilistic relevance feedback next up previous contents index next an appraisal and some up the binary independence model previous probability estimates in practice contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
