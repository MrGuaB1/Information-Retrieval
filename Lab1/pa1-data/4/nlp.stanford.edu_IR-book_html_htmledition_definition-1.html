definition next up previous contents index next the pagerank computation up markov chains previous markov chains contents index definition a markov chain is said to be ergodic if there exists a positive integer such that for all pairs of states in the markov chain if it is started at time 0 in state then for all the probability of being in state at time is greater than for a markov chain to be ergodic two technical conditions are required of its states and the non zero transition probabilities these conditions are known as irreducibility and aperiodicity informally the first ensures that there is a sequence of transitions of non zero probability from any state to any other while the latter ensures that the states are not partitioned into sets such that all state transitions occur cyclically from one set to another theorem for any ergodic markov chain there is a unique steady state probability vector that is the principal left eigenvector of such that if is the number of visits to state in steps then 254 where is the steady state probability for state end theorem it follows from theorem 21.2 1 that the random walk with teleporting results in a unique distribution of steady state probabilities over the states of the induced markov chain this steady state probability for a state is the pagerank of the corresponding web page next up previous contents index next the pagerank computation up markov chains previous markov chains contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
