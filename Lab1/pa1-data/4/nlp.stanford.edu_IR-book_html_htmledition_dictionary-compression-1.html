dictionary compression next up previous contents index next dictionary as a string up index compression previous zipf's law modeling the contents index dictionary compression this section presents a series of dictionary data structures that achieve increasingly higher compression ratios the dictionary is small compared with the postings file as suggested by table 5.1 so why compress it if it is responsible for only a small percentage of the overall space requirements of the ir system one of the primary factors in determining the response time of an ir system is the number of disk seeks necessary to process a query if parts of the dictionary are on disk then many more disk seeks are necessary in query evaluation thus the main goal of compressing the dictionary is to fit it in main memory or at least a large portion of it to support high query throughput although dictionaries of very large collections fit into the memory of a standard desktop machine this is not true of many other application scenarios for example an enterprise search server for a large corporation may have to index a multiterabyte collection with a comparatively large vocabulary because of the presence of documents in many different languages we also want to be able to design search systems for limited hardware such as mobile phones and onboard computers other reasons for wanting to conserve memory are fast startup time and having to share resources with other applications the search system on your pc must get along with the memory hogging word processing suite you are using at the same time figure 5.3 storing the dictionary as an array of fixed width entries subsections dictionary as a string blocked storage next up previous contents index next dictionary as a string up index compression previous zipf's law modeling the contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
