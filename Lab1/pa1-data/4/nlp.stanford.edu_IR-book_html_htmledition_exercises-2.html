exercises next up previous contents index next support vector machines and up vector space classification previous references and further reading contents index exercises exercises in figure 14.13 which of the three vectors and is i most similar to according to dot product similarity ii most similar to according to cosine similarity iii closest to according to euclidean distance download reuters 21578 and train and test rocchio and knn classifiers for the classes acquisitions corn crude earn grain interest money fx ship trade and wheat use the modapte split you may want to use one of a number of software packages that implement rocchio classification and knn classification for example the bow toolkit mccallum 1996 download 20 newgroups page 8.2 and train and test rocchio and knn classifiers for its 20 classes show that the decision boundaries in rocchio classification are as in knn given by the voronoi tessellation computing the distance between a dense centroid and a sparse vector is for a naive implementation that iterates over all dimensions based on the equality and assuming that has been precomputed write down an algorithm that is instead where is the number of distinct terms in the test document prove that the region of the plane consisting of all points with the same nearest neighbors is a convex polygon design an algorithm that performs an efficient 1nn search in 1 dimension where efficiency is with respect to the number of documents what is the time complexity of the algorithm design an algorithm that performs an efficient 1nn search in 2 dimensions with at most polynomial in preprocessing time can one design an exact efficient algorithm for 1nn for very large along the ideas you used to solve the last exercise show that equation 145 defines a hyperplane with and figure 14.14 a simple non separable set of points we can easily construct non separable data sets in high dimensions by embedding a non separable set like the one shown in figure 14.14 consider embedding figure 14.14 in 3d and then perturbing the 4 points slightly ie moving them a small distance in a random direction why would you expect the resulting configuration to be linearly separable how likely is then a non separable set of points in dimensional space assuming two classes show that the percentage of non separable assignments of the vertices of a hypercube decreases with dimensionality for for example for the proportion of non separable assignments is 0 for it is one of the two non separable cases for is shown in figure 14.14 the other is its mirror image solve the exercise either analytically or by simulation although we point out the similarities of naive bayes with linear vector space classifiers it does not make sense to represent count vectors the document representations in nb in a continuous vector space there is however a formalization of nb that is analogous to rocchio show that nb assigns a document to the class represented as a parameter vector whose kullback leibler kl divergence section 12.4 page 12.4 to the document represented as a count vector as in section 13.4 1 page normalized to sum to 1 is smallest next up previous contents index next support vector machines and up vector space classification previous references and further reading contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
