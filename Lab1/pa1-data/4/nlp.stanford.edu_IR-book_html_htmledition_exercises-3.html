exercises next up previous contents index next hierarchical clustering up flat clustering previous references and further reading contents index exercises exercises let be a clustering that exactly reproduces a class structure and a clustering that further subdivides some clusters in show that show that mutual information is symmetric in the sense that its value does not change if the roles of clusters and classes are switched which of the other three evaluation measures are symmetric in this sense compute rss for the two clusterings in figure 16.7 i give an example of a set of points and three initial centroids which need not be members of the set of points for which 3 means converges to a clustering with an empty cluster ii can a clustering with an empty cluster be the global optimum with respect to rss download reuters 21578 discard documents that do not occur in one of the 10 classes acquisitions corn crude earn grain interest money fx ship trade and wheat discard documents that occur in two of these 10 classes i compute a means clustering of this subset into 10 clusters there are a number of software packages that implement means such as weka witten and frank 2005 and r r development core team 2005 ii compute purity normalized mutual information and ri for the clustering with respect to the 10 classes iii compile a confusion matrix table 14.5 page 14.5 for the 10 classes and 10 clusters identify classes that give rise to false positives and false negatives prove that is monotonically decreasing in there is a soft version of means that computes the fractional membership of a document in a cluster as a monotonically decreasing function of the distance from its centroid eg as modify reassignment and recomputation steps of hard means for this soft version in the last iteration in table 16.3 document 6 is in cluster 2 even though it was the initial seed for cluster 1 why does the document change membership the values of the parameters in iteration 25 in table 16.3 are rounded what are the exact values that em will converge to perform a means clustering for the documents in table 16.3 after how many iterations does means converge compare the result with the em clustering in table 16.3 and discuss the differences modify the expectation and maximization steps of em for a gaussian mixture the maximization step computes the maximum likelihood parameter estimates and for each of the clusters the expectation step computes for each vector a soft assignment to clusters gaussians based on their current parameters write down the equations for gaussian mixtures corresponding to and 202 show that means can be viewed as the limiting case of em for gaussian mixtures if variance is very small and all covariances are 0 the within point scatter of a clustering is defined as show that minimizing rss and minimizing within point scatter are equivalent derive an aic criterion for the multivariate bernoulli mixture model from equation 196 next up previous contents index next hierarchical clustering up flat clustering previous references and further reading contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
