hierarchical clustering next up previous contents index next hierarchical agglomerative clustering up irbook previous exercises contents index hierarchical clustering flat clustering is efficient and conceptually simple but as we saw in chapter 16 it has a number of drawbacks the algorithms introduced in chapter 16 return a flat unstructured set of clusters require a prespecified number of clusters as input and are nondeterministic hierarchical clustering or hierarchic clustering outputs a hierarchy a structure that is more informative than the unstructured set of clusters returned by flat clustering hierarchical clustering does not require us to prespecify the number of clusters and most hierarchical algorithms that have been used in ir are deterministic these advantages of hierarchical clustering come at the cost of lower efficiency the most common hierarchical clustering algorithms have a complexity that is at least quadratic in the number of documents compared to the linear complexity of means and em cf section 16.4 page 16.4 this chapter first introduces agglomerative hierarchical clustering section 17.1 and presents four different agglomerative algorithms in sections 17.2 17.4 which differ in the similarity measures they employ single link complete link group average and centroid similarity we then discuss the optimality conditions of hierarchical clustering in section 17.5 section 17.6 introduces top down or divisive hierarchical clustering section 17.7 looks at labeling clusters automatically a problem that must be solved whenever humans interact with the output of clustering we discuss implementation issues in section 17.8 section 17.9 provides pointers to further reading including references to soft hierarchical clustering which we do not cover in this book there are few differences between the applications of flat and hierarchical clustering in information retrieval in particular hierarchical clustering is appropriate for any of the applications shown in table 16.1 page 16.1 see also section 16.6 page 16.6 in fact the example we gave for collection clustering is hierarchical in general we select flat clustering when efficiency is important and hierarchical clustering when one of the potential problems of flat clustering not enough structure predetermined number of clusters non determinism is a concern in addition many researchers believe that hierarchical clustering produces better clusters than flat clustering however there is no consensus on this issue see references in section 17.9 subsections hierarchical agglomerative clustering single link and complete link clustering time complexity of hac group average agglomerative clustering centroid clustering optimality of hac divisive clustering cluster labeling implementation notes references and further reading exercises next up previous contents index next hierarchical agglomerative clustering up irbook previous exercises contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
