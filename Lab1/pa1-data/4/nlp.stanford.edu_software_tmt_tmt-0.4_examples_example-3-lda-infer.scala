stanford tmt example 3 lda inference on a new dataset http nlp stanford edu software tmt 0.4 tells scala where to find the tmt classes import scalanlp io _ import scalanlp stage _ import scalanlp stage text _ import scalanlp text tokenize _ import scalanlp pipes pipes global _ import edu stanford nlp tmt stage _ import edu stanford nlp tmt model lda _ import edu stanford nlp tmt model llda _ the path of the model to load val modelpath file lda 59ea15c7 30 75faccf7 println loading modelpath val model loadcvb0lda modelpath or for a gibbs model use val model loadgibbslda modelpath a new dataset for inference here we use the same dataset that we trained against but this file could be something new val source csvfile pubmed oa subset csv idcolumn 1 val text source read from the source file column 4 select column containing text tokenizewith model tokenizer get tokenize with existing model's tokenizer base name of output files to generate val output file modelpath source meta java io file getname replaceall csv turn the text into a dataset ready to be used with lda val dataset ldadataset text termindex model termindex println writing document distributions to output+ document topic distributions csv val perdoctopicdistributions infercvb0documenttopicdistributions model dataset csvfile output+ document topic distributuions csv write perdoctopicdistributions println writing topic usage to output+ usage csv val usage querytopicusage model dataset perdoctopicdistributions csvfile output+ usage csv write usage println estimating per doc per word topic distributions val perdocwordtopicdistributions estimateperwordtopicdistributions model dataset perdoctopicdistributions println writing top terms to output+ top terms csv val topterms querytopterms model dataset perdocwordtopicdistributions numtopterms 50 csvfile output+ top terms csv write topterms
