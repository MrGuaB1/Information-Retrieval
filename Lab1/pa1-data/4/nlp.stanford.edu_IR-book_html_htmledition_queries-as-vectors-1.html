queries as vectors next up previous contents index next computing vector scores up the vector space model previous dot products contents index queries as vectors there is a far more compelling reason to represent documents as vectors we can also view a query as a vector consider the query jealous gossip this query turns into the unit vector on the three coordinates of figures 6.12 and 6.13 the key idea now to assign to each document a score equal to the dot product 26 in the example of figure 6.13 wuthering heights is the top scoring document for this query with a score of 0.509 with pride and prejudice a distant second with a score of 0.085 and sense and sensibility last with a score of 0.074 this simple example is somewhat misleading the number of dimensions in practice will be far larger than three it will equal the vocabulary size to summarize by viewing a query as a bag of words we are able to treat it as a very short document as a consequence we can use the cosine similarity between the query vector and a document vector as a measure of the score of the document for that query the resulting scores can then be used to select the top scoring documents for a query thus we have 27 a document may have a high cosine score for a query even if it does not contain all query terms note that the preceding discussion does not hinge on any specific weighting of terms in the document vector although for the present we may think of them as either tf or tf idf weights in fact a number of weighting schemes are possible for query as well as document vectors as illustrated in example 6.3 2 and developed further in section 6.4 computing the cosine similarities between the query vector and each document vector in the collection sorting the resulting scores and selecting the top documents can be expensive a single similarity computation can entail a dot product in tens of thousands of dimensions demanding tens of thousands of arithmetic operations in section 7.1 we study how to use an inverted index for this purpose followed by a series of heuristics for improving on this worked example we now consider the query best car insurance on a fictitious collection with documents where the document frequencies of auto best car and insurance are respectively 5000 50000 10000 and 1000 term query document product tf df idf tf wf auto 0 5000 2.3 0 1 1 0.41 0 best 1 50000 1.3 1.3 0 0 0 0 car 1 10000 2.0 2.0 1 1 0.41 0.82 insurance 1 1000 3.0 3.0 2 2 0.82 2.46 in this example the weight of a term in the query is simply the idf and zero for a term not in the query such as auto this is reflected in the column header the entry for auto is zero because the query does not contain the termauto for documents we use tf weighting with no use of idf but with euclidean normalization the former is shown under the column headed wf while the latter is shown under the column headed invoking 23 now gives a net score of end worked example next up previous contents index next computing vector scores up the vector space model previous dot products contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
