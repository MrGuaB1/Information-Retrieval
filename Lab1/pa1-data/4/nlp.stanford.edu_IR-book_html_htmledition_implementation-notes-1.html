implementation notes next up previous contents index next references and further reading up hierarchical clustering previous cluster labeling contents index implementation notes most problems that require the computation of a large number of dot products benefit from an inverted index this is also the case for hac clustering computational savings due to the inverted index are large if there are many zero similarities either because many documents do not share any terms or because an aggressive stop list is used in low dimensions more aggressive optimizations are possible that make the computation of most pairwise similarities unnecessary exercise 17.10 however no such algorithms are known in higher dimensions we encountered the same problem in knn classification see section 14.7 page 14.7 when using gaac on a large document set in high dimensions we have to take care to avoid dense centroids for dense centroids clustering can take time where is the size of the vocabulary whereas complete link clustering is where is the average size of the vocabulary of a document so for large vocabularies complete link clustering can be more efficient than an unoptimized implementation of gaac we discussed this problem in the context of means clustering in chapter 16 page 16.4 and suggested two solutions truncating centroids keeping only highly weighted terms and representing clusters by means of sparse medoids instead of dense centroids these optimizations can also be applied to gaac and centroid clustering even with these optimizations hac algorithms are all or and therefore infeasible for large sets of 1000000 or more documents for such large sets hac can only be used in combination with a flat clustering algorithm like means recall that means requires a set of seeds as initialization figure 16.5 page 16.5 if these seeds are badly chosen then the resulting clustering will be of poor quality we can employ an hac algorithm to compute seeds of high quality if the hac algorithm is applied to a document subset of size then the overall runtime of means cum hac seed generation is this is because the application of a quadratic algorithm to a sample of size has an overall complexity of an appropriate adjustment can be made for an algorithm to guarantee linearity this algorithm is referred to as the buckshot algorithm it combines the determinism and higher reliability of hac with the efficiency of means next up previous contents index next references and further reading up hierarchical clustering previous cluster labeling contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
