references and further reading next up previous contents index next web search basics up matrix decompositions and latent previous latent semantic indexing contents index references and further reading strang 1986 provides an excellent introductory overview of matrix decompositions including the singular value decomposition theorem 18.3 is due to eckart and young 1936 the connection between information retrieval and low rank approximations of the term document matrix was introduced in deerwester et al 1990 with a subsequent survey of results in berry et al 1995 dumais 1993 and dumais 1995 describe experiments on trec benchmarks giving evidence that at least on some benchmarks lsi can produce better precision and recall than standard vector space retrieval http www cs utk edu berry lsi++ and http lsi argreenhouse com lsi lsipapers html offer comprehensive pointers to the literature and software of lsi schutze and silverstein 1997 evaluate lsi and truncated representations of centroids for efficient means clustering section 16.4 bast and majumdar 2005 detail the role of the reduced dimension in lsi and how different pairs of terms get coalesced together at differing values of applications of lsi to cross language information retrieval where documents in two or more different languages are indexed and a query posed in one language is expected to retrieve documents in other languages are developed in berry and young 1995 and littman et al 1998 lsi referred to as lsa in more general settings has been applied to host of other problems in computer science ranging from memory modeling to computer vision hofmann 1999a b provides an initial probabilistic extension of the basic latent semantic indexing technique a more satisfactory formal basis for a probabilistic latent variable model for dimensionality reduction is the latent dirichlet allocation lda model blei et al 2003 which is generative and assigns probabilities to documents outside of the training set this model is extended to a hierarchical clustering by rosen zvi et al 2004 wei and croft 2006 present the first large scale evaluation of lda finding it to significantly outperform the query likelihood model of section 12.2 page but to not perform quite as well as the relevance model mentioned in section 12.4 page but the latter does additional per query processing unlike lda teh et al 2006 generalize further by presenting hierarchical dirichlet processes a probabilistic model which allows a group for us a document to be drawn from an infinite mixture of latent topics while still allowing these topics to be shared across documents exercises assume you have a set of documents each of which is in either english or in spanish the collection is given in figure 18.4 figure documents for exercise 18.5 figure 18.5 gives a glossary relating the spanish and english words above for your own information this glossary is not available to the retrieval system figure 18.5 glossary for exercise 18.5 construct the appropriate term document matrix to use for a collection consisting of these documents for simplicity use raw term frequencies rather than normalized tf idf weights make sure to clearly label the dimensions of your matrix write down the matrices and and from these derive the rank 2 approximation state succinctly what the entry in the matrix represents state succinctly what the entry in the matrix represents and why it differs from that in next up previous contents index next web search basics up matrix decompositions and latent previous latent semantic indexing contents index 2008 cambridge university press this is an automatically generated page in case of formatting errors you may want to look at the pdf edition of the book 2009 04 07
